# Analyzing Nashville Police Service Calls# Dataset: https://data.nashville.gov/Police/Metro-Nashville-Police-Department-Calls-for-Servic/kwnd-qrrm# Questions:# 1. Does nothing good happen after midnight?#      - What are the crime trends day vs. night? How is each addressed?# 2. Are service calls more for emergencies or basic protect and observe?# 3. What are the crime trends in Nashville vs. Tampa?#      - Personal curiosity# Tasks:# Import Packages# Load in Data# Data Cleaning# Export Data for Tableau# Data Wrangling/EDA - TABLEAU#Import Packagesimport pandas as pd#Load in Datapolice = pd.read_csv("/Users/michaelwilt/Desktop/Ramsey Project/Metro_Nashville_Police_Department_Calls_for_Service.csv")police.info()#Look at our missing datapolice.isna().sum().sum()police["Tencode Description"].isna().sum()police["Unit Dispatched"].isna().sum()police["Unit Dispatched"].value_counts().sum()police.Zone.isna().sum()police.Zone.value_counts().sum()## Data Cleaning# 1. Transform "Call Received" to Datetime and separate data and time# 2. We will drop NA values using "Tencode Description" as our variable#     - The amount of na values is roughly 2.7% of the overall values in this column#     - We need our Tencode Descriptions to understand the types of calls# 3. We recognize the amount of NA values is much higher in "Unit Dispatched" and in "Zone" (7.2% & 14.8% respectively)#     - We won't touch these values as to not affect the overall amount of calls#Create new variable to keeps original data intactpolice1 = policepolice2 = police1['Call Received'].str.split(' ', expand=True).rename(columns = lambda x: "Date"+str(x+1))#Transform and shape our columnspolice2.Date2 = police2.Date2.astype(str)police2.Date3 = police2.Date3.astype(str)police2["Time"] = police2.Date2 + " " + police2.Date3#Transform Date and Time to datetime formatspolice2.Date1 = pd.to_datetime(police2.Date1).dt.datepolice2.Time = pd.to_datetime(police2.Time).dt.timepolice2["Date"] = police2.Date1#Create 3 new variables # - 1 with only date and time columns # - 2 combining it with the police1 dataframe# - 3 a frame to house specific columns for analysispolice3 = police2.drop(["Date1", "Date2", "Date3"], axis = 1)police4 = pd.concat([police1, police3], axis = 1)police5 = police4[["Date", "Time", "Tencode", "Tencode Description", "Unit Dispatched", "Shift", "Zone"]]police5.head()# Handling our NA valuespolice5.isna().sum()#Fill our na values for Unit Dispatched and Zonepolice6 = police5.fillna({"Unit Dispatched" : "0000", "Zone" : "000"})#Drop rest of NA value rowspolice6.isna().sum()police6.value_counts().sum()police7 = police6.dropna(how='any', axis=0)police7.isna().sum()police7.head()police7.to_csv(r'/Users/michaelwilt/Desktop/Ramsey Project/Exported FIles/nashPolice.csv', index=False)